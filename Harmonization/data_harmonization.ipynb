{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download from GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install pydrive\n",
    "\n",
    "# !pip install pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/drive/u/1/folders/1SPuEOjOZIOm8mJkOqZKB7r0Bw1qgOMh5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Use gdown to download the folder\n",
    "# import gdown\n",
    "\n",
    "\n",
    "# # Convert the folder URL to a format that gdown can use\n",
    "# folder_id = url.split('/')[-1]\n",
    "# gdown.download_folder(f'https://drive.google.com/drive/folders/{folder_id}', quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonization Parameters Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sensor_data(csv_list):\n",
    "    # csv_list = glob.glob('Lauren purpleair data\\\\*\\\\*.csv')\n",
    "\n",
    "    csv_list\n",
    "    sensor_dataframes = []\n",
    "\n",
    "    for idx,csv_path in enumerate(csv_list):\n",
    "            \n",
    "        sensor_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if len(sensor_df.columns) < 4:\n",
    "            sensor_df = pd.read_csv(csv_path,delimiter=';')\n",
    "        sensor_dataframes.append(sensor_df)\n",
    "    return sensor_dataframes\n",
    "\n",
    "csv_list = glob.glob('Lauren purpleair data\\\\*\\\\*.csv')\n",
    "sensor_dataframes = read_sensor_data(csv_list) #[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_units_dict(df):\n",
    "    units_dict = {}\n",
    "    for column in df.columns:\n",
    "        units_dict[column] = df.loc[0, column]\n",
    "    return units_dict\n",
    "\n",
    "units_dict = create_units_dict(sensor_dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sensor_dataframes(sensor_dataframes):\n",
    "\n",
    "    numeric_columns = ['pm2.5_atm_b', 'pm2.5_cf_1', 'pm2.5_cf_1_a', 'pm2.5_cf_1_b',\t'pm10.0_atm', 'pm10.0_atm_a', 'pm10.0_atm_b', 'pm10.0_cf_1', 'pm10.0_cf_1_a', 'pm10.0_cf_1_b']\n",
    "    \n",
    "    \n",
    "    cleaned_dataframes = []\n",
    "    for idx,sensor_df in enumerate(sensor_dataframes):\n",
    "        # remove header\n",
    "        sensor_df = sensor_df.iloc[1:]\n",
    "        # Sort by 'Timestamp'\n",
    "        try:\n",
    "            sensor_df = sensor_df.sort_values(by=['time_stamp']).reset_index()\n",
    "        except:\n",
    "            print(idx)\n",
    "            display(sensor_df)\n",
    "            break\n",
    "        # Change 'Timestamp' to date format\n",
    "        sensor_df['time_stamp'] = pd.to_datetime(sensor_df['time_stamp'])\n",
    "\n",
    "\n",
    "\n",
    "        # Filter rows based on timestamp\n",
    "        # sensor_df = sensor_df[sensor_df['time_stamp'] <= '2024-02-10']\n",
    "\n",
    "        # Convert the 'time_stamp' column to datetime\n",
    "        sensor_df['time_stamp'] = pd.to_datetime(sensor_df['time_stamp']).dt.date\n",
    "        # Perform the comparison using datetime\n",
    "        comparison_date = datetime(2024, 2, 10).date()\n",
    "        sensor_df = sensor_df[sensor_df['time_stamp'] <= comparison_date]\n",
    "        \n",
    "        try:\n",
    "            sensor_df = sensor_df.sort_values(by=['time_stamp']).reset_index()\n",
    "        except:\n",
    "            print(idx)\n",
    "            print(sensor_df)\n",
    "            break\n",
    "\n",
    "            # Convert specified columns to numeric\n",
    "        sensor_df[numeric_columns] = sensor_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "        # Append the cleaned DataFrame to the list\n",
    "        cleaned_dataframes.append(sensor_df)\n",
    "    return cleaned_dataframes\n",
    "\n",
    "cleaned_sensor_dataframes = clean_sensor_dataframes(sensor_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sensor_dataframes[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = [csv_path.split('\\\\')[1] for csv_path in csv_list] #[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_sensor_data(sensor_dataframes, column_name):\n",
    "    # Extracting the specified column from each sensor dataframe\n",
    "    cutoff_value = len(sensor_dataframes[3])\n",
    "    selected_columns = [df[column_name] for df in sensor_dataframes]\n",
    "    # Combining these columns into a new dataframe\n",
    "    combined_df = pd.concat(selected_columns, axis=1)[:cutoff_value]\n",
    "    combined_df.columns = [f'Sensor{i+1}' for i in range(len(sensor_dataframes))]\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_data(column_name, sensor_dataframes, sensor_names, units_dict, window_size=10):\n",
    "    # Calculate the rolling median\n",
    "    df = aggregate_sensor_data(sensor_dataframes,column_name)\n",
    "    rolling_median = df.rolling(window=10, min_periods=1).median()\n",
    "    for sensor_df, sensor_name in zip(sensor_dataframes, sensor_names):\n",
    "        plt.plot(sensor_df['time_stamp'], sensor_df[column_name], label=sensor_name)\n",
    "        \n",
    "    plt.plot(sensor_dataframes[3]['time_stamp'], rolling_median.median(axis=1), color='black', linestyle='dashed', label='Median')\n",
    "    plt.xlabel('time_stamp')\n",
    "    plt.ylabel(f'{column_name} ({units_dict[column_name]})')\n",
    "    plt.title(f'{column_name} Data for Sensors')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=20, ha='right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_sensor_data('pm2.5_atm_b', cleaned_sensor_dataframes, sensor_names, units_dict, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to fit each sensor's data to the linear function\n",
    "def fit_sensor_to_median(x, y):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    return lr.coef_[0], lr.intercept_  # Return the coefficients and intercept of the linear regression model\n",
    "\n",
    "def fit_sensor_data(column_name, sensor_dataframes, sensor_names, units_dict, window_size=10, num_dataframes=1):\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "\n",
    "    cutoff_value = 1000 #len(sensor_dataframes[3]) - 100\n",
    "\n",
    "    num_dataframes = num_dataframes\n",
    "    sensor_dataframes_working = sensor_dataframes[:num_dataframes]\n",
    "    sensor_names_wokring = sensor_names[:num_dataframes]\n",
    "\n",
    "    df = aggregate_sensor_data(sensor_dataframes, column_name)\n",
    "    rolling_median = df.rolling(window=window_size, min_periods=1).median()\n",
    "    fitted_data_dict = {}\n",
    "    coefficients_data = []\n",
    "\n",
    "    for sensor_df, sensor_name in zip(sensor_dataframes_working, sensor_names_wokring):\n",
    "        X = sensor_df[column_name].to_frame(name=column_name)[:cutoff_value]\n",
    "        Y = rolling_median.median(axis=1).to_frame('median')[:cutoff_value]\n",
    "        coefficients, intercept = fit_sensor_to_median(X, Y)\n",
    "        fitted_data = X * coefficients + intercept\n",
    "        fitted_data = fitted_data.values.flatten()\n",
    "        fitted_data_dict[sensor_name] = fitted_data\n",
    "        \n",
    "        # Append coefficients and intercept to list\n",
    "        coefficients_data.append({\n",
    "            'Sensor': sensor_name,\n",
    "            'Coefficient': coefficients[0],\n",
    "            'Intercept': intercept[0]\n",
    "        })\n",
    "\n",
    "    # Create DataFrame from the list of coefficients and intercepts\n",
    "    coefficients_df = pd.DataFrame(coefficients_data)\n",
    "    return coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['pm2.5_atm_b', 'pm2.5_cf_1', 'pm2.5_cf_1_a', 'pm2.5_cf_1_b',\t'pm10.0_atm', 'pm10.0_atm_a', 'pm10.0_atm_b', 'pm10.0_cf_1', 'pm10.0_cf_1_a', 'pm10.0_cf_1_b']\n",
    "\n",
    "for column_name in numeric_columns:\n",
    "    coefficients_df = fit_sensor_data(column_name, cleaned_sensor_dataframes, sensor_names, units_dict, window_size=1, num_dataframes= 15) #len(sensor_dataframes))\n",
    "    filename = f\"{column_name.lower().replace(' ', '_')}_coefficients_df.csv\"\n",
    "    coefficients_df.to_csv(filename, index=False)\n",
    "    print(f\"{filename} saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
